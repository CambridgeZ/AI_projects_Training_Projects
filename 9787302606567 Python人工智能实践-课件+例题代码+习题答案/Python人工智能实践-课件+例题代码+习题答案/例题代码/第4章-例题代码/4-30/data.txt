人工智能经历几波浪潮之后，在过去十年中基本实现了感知能力，但却无法做到推理、可解释等认知能力，因此在下一波人工智能浪潮兴起时，将主要会去实现具有推理、可解释性、认知的人工智能。2015 年，张钹院士提出第三代人工智能体系的雏形。2017 年，DARPA 发起XAI 项目，核心思想是从可解释的机器学习系统、人机交互技术以及可解释的心理学理论三个方面，全面开展可解释性AI 系统的研究。2018 年底，第三代人工智能的理论框架体系正式公开提出，核心思想为：（1）建立可解释、鲁棒性的人工智能理论和方法；（2）发展安全、可靠、可信及可扩展的人工智能技术；（3）推动人工智能创新应用。其中具体实施的路线包括：（1）与脑科学融合，发展脑启发的人工智能理论；（2）探索数据与知识融合的人工智能理论与方法。虽然还没有明确第三代人工智能是什么，但是其趋势是清晰的。Gartner 2020 年人工智能技术成熟度曲线图显示。2020 年人工智能技术成熟度曲线共有30 项技术出现，其中有17 项技术需要2 到5 年才能达到成熟期，有8 项技术需要5 到10 年才能达到成熟期。出现的这些技术基本处于创新萌芽期、期望膨胀的顶峰期和泡沫低谷期，而“稳步爬升的光明期”和“实质生产的高峰期”出现的技术寥寥无几，仅有Insight Engines（洞察引擎）和 GPUAccelerators （GPU 加速器）。
通过对2020 年人工智能技术成熟度曲线分析，并结合人工智能的发展现状，本报告认为人工智能下一个十年重点发展的方向包括：强化学习（Reinforement Learning）、神经形态硬件（Neuromorphic Hardware）、知识图谱（Knowledge Graphics）、智能机器人（Smart Robotics）、可解释性AI（Explainable AI）、数字伦理Digital Ethics）、自然语言处理（Natural Language Processing）等技术处于期望膨胀期，表明人们对AI 最大的期待，达到稳定期需要5-10 年，是AI 未来十年重点发展方向。
（1） 强化学习（Reinforement Learning）。强化学习用于描述和解决智能体在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题。强化学习不受标注数据和先验知识所限制，而是通过接收环境对动作的奖励（反馈）获得学习信息并更新模型参数。由于智能体和环境的交互方式与人类和环境的交互方式类似，强化学习可以认为是一套通用的学习框架，可用来解决通用人工智能的问题。
（2） 神经形态硬件（Neuromorphic Hardware）。神经形态硬件旨在用与传统硬件完全不同的方式处理信息，通过模仿人脑构造来大幅提高计算机的思维能力与反应能力。采用多进制信号来模拟生物神经元的功能，可将负责数据存储和数据处理的元件整合到同一个互联模块当中。从这一意义上说，这一系统与组成人脑的数十亿计的、相互连接的神经元颇为相仿。神经形态硬件能够大幅提升数据处理能力和机器学习能力，能耗和体积却要小得多，为人工智能的未来发展提供强大的算力支撑。
（3） 知识图谱（Knowledge Graphics）。要实现真正的类人智能，机器还需要掌握大量的常识性知识，以人的思维模式和知识结构来进行语言理解、视觉场景解析和决策分析。知识图谱将互联网的信息表达成更接近人类认知世界的形式，提供了一种更好地组织、管理和理解互联网海量信息的能力，被认为是从感知智能通往认知智能的重要基石。从感知到认知的跨越过程中，构建大规模高质量知识图谱是一个重要环节，当人工智能可以通过更结构化的表示理解人类知识，并进行互联，才有可能让机器真正实现推理、联想等认知功能。清华大学唐杰教授在知识图谱的基础上提出的“认知图谱=知识图谱+认知推理+逻辑表达”，为人工智能未来十年的发展提供了研究方向[79]。
（4） 智能机器人（Intelligent Robot）。智能机器人需要具备三个基本要素：感觉要素、思考要素和反应要素。感觉要素是利用传感器感受内部和外部信息，如视觉、听觉、触觉等；思考要素是根据感觉要素所得到的信息，思考出采用什么样的动作；反应要素是对外界做出反应性动作。智能机器人的关键技术包括多传感器信息融合、导航与定位、路径规划、智能控制等。由于社会发展的需求和机器人应用行业的扩大，机器人可以具备的智能水平并未达到极限，影响因素包括硬件设施的计算速度不够、传感器的种类不足，以及缺乏机器人的思考行为程序难以编制等。
（5） 可解释人工智能（Explainable AI）。虽然深度学习算法在语音识别、计算机视觉、自然语言处理等领域取得令人印象深刻的性能，但是它们在透明度和可解释性方面仍存在局限性。深度学习的不可解释性已经成为计算机领域顶级会议（如NIPS）火药味十足的讨论话题。一些方法尝试将黑盒的神经网络模型和符号推理结合了起来，通过引入逻辑规则增加可解释性。此外，符号化的知识图谱具有形象直观的特性，为弥补神经网络在解释性方面的缺陷提供了可能。利用知识图谱解释深度学习和高层次决策模型，是当前值得研究的科学问题，可以为可解释的AI 提供全新视角的机遇。张钹院士指出当前人工智能的最大问题是不可解释和不可理解，并提倡建立具有可解释性的第三代人工智能理论体系[80]。
（6） 数字伦理（Digital Ethics）。作为新一轮科技革命和产业变革的重要驱动力，人工智能已上升为国家战略，人工智能将会在未来几十年对人类社会产生巨大的影响，带来不可逆转的改变。人工智能的发展面临诸多现实的伦理和法律问题，如网络安全、个人隐私、数据权益和公平公正等。为了让人工智能技术更好地服务于经济社会发展和人民美好生活，不仅要发挥好人工智能的“头雁”效应，也要加强人工智能相关法律、伦理、社会问题等方面的研究。数字伦理将是未来智能社会的发展基石，只有建立完善的人工智能伦理规范，处理好机器与人的新关系，我们才能更多地获得人工智能红利，让技术造福人类。
（7） 自然语言处理（Nature Language Processing）。深度学习在自然语言处理取得了巨大突破，它能够高效学习多粒度语言单元间复杂语义关联。但是仅仅依靠深度学习并不能完成对自然语言的深度理解。对自然语言的深度理解需要从字面意义到言外之意的跃迁，这需要引入复杂知识的支持。丰富的语言知识能够提升模型的可解释性，可覆盖长尾低频语言单位的知识规则能够提升模型的可扩展性，而异质多样的知识与推理体系能够提升模型鲁棒性。因此有必要研究知识指导的自然语言处理技术，揭示自然语言处理和知识产生及表达的机理，建立知识获取与语言处理双向驱动的方法体系，实现真正的语言与知识智能理解。透过历史可以发现，每一次的经济大发展都与科技的突破紧密相关。种种迹象表明科技正迎来新的爆发期，全球科技竞赛也将再次掀起高潮。中国想要在这轮科技革新中占得先机，就需要加强技术预判，找准方向，提早部署，特别是在一些基础性、突破性的领域精准布局。